%% Evaluate In-sample Performance
% * Filename: evaluate_in.m
% * Authors: Matt Reimer
% * Created: 02/05/19
% * Updated: 07/08/19
% * Purpose: Function that returns various evaluation criteria of the
% different estimators.
%
%% Description
% * The function |evaluate_in| calculates various performance metrics for
% the estimates generated by different estimators.
%
%% Notes
% * Called by: |monte_carlo_analysis|
%
function results = evaluate_in(est,dat,params)
%% Input arguments:
% * |est| = a structural array of parameter estimates.
% * |dat| = a structural array of data from dgp.
% * |par| = a structural array of dgp parameters.
%
%% Output arguments:
% * |results| = a structural array of in-sample results
%
%% Preliminaries
    K = size(params(1).btrue,1);
    fields = fieldnames(est);
    draws = numel(params);
    fprintf('CALCULATING IN-SAMPLE PERFORMANCE METRICS...'); tic;

%% In-Sample Performance Metrics
    for i = 1:numel(fields)
        scenario = fields{i};
        for j = 1:draws
            % Parameter Bias
            bias.(scenario)(1:K,j) = 100*(est.(scenario)(j).b(1:K) - ...
                params(j).btrue)./params(j).btrue;
            % Probability RMSE
            rmse.(scenario)(j) = ((est.(scenario)(j).prob(:) - ...
                dat(j).prob(:))'*(est.(scenario)(j).prob(:) - ...
                dat(j).prob(:)))^(1/2);
        end
    end
    time = toc;
    fprintf('Finished: Total Time = %d seconds.\n\n',time);
    
    % Output
    results = struct('bias',bias,'rmse',rmse);
    
end
    
        
        
        
        
        